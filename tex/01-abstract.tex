%!TEX root = ../thesis.tex
\chapter*{\englishabstractname}
\addcontentsline{toc}{chapter}{\englishabstractname}
% Multilayer Perceptrons for Learning to Branch
%
This thesis evaluates ablations of a Graph Convolutional Neural Networks for machine learning aided branching proposed by Gasse et al. (2019) \cite{gasse2019exact}
for faster solving Mixed-Integer Linear Programming (\gls{MILP}) problems. 
Efficient \gls{MILP} solution algorithms are important for real-time optimization in various industries, including industrial production, logistics, transportation, and energy production \cite{junger2010years}.  Reduced computation time via merging Machine learning with the Branch and Bound solution algorithm can improve these algorithms without sacrificing the strong benefits of global optimization.
%Multiple central researchers within mathematical programming and machine learning have recently shown interest in the application of Machine Learning in \gls{MILP} \cite{bengio2020machine,bertsimas2019online}, particularly in the variable selection part of the branching strategy \cite{khalil2020towards}.
In 2019, reliable results of improvement over top branching strategies in open-source solvers were shown \cite{gasse2019exact}, and in 2020 these methods have been expanded to purely \gls{CPU}-based solutions \cite{gupta2020hybrid}. Different network topologies and feature sets on both \gls{CPU}s and \gls{GPU}s have been presented, however, the trade-off between accuracy and efficiency with these models on varying hardware is still mostly unexplored.
In order to address this, two variants of Graph Convolutional Neural Networks and three Multi-Layer Perceptron configurations are trained via imitation learning on the Strong Branching algorithm on generated \gls{MILP} problems using the new framework \textit{Ecole} \cite{prouvost2020ecole,prouvost2021ecole}.  The models are then incorporated into the \gls{SCIP} optimization solver and evaluated on test problems. All models show near state-of-the-art efficiency when run on the \gls{GPU}. The models containing graph convolutions show a large loss of efficiency when run on the \gls{CPU} rather than the \gls{GPU}.
%Future research should attempt to implement these methods on practical optimization problems, as well as compare results to the current top proprietary solvers after parameter optimization \cite{hutter2010automated}. 

The code for this project is available at\\ \url{https://github.com/Sandbergo/branch2learn}

%
\clearpage
