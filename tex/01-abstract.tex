%!TEX root = ../thesis.tex
\chapter*{\englishabstractname}
\addcontentsline{toc}{chapter}{\englishabstractname}
% Multilayer Perceptrons for Learning to Branch
%
This project evaluates Multi-layer Perceptrons for machine learning aided branching proposed by Gupta et al. \cite{gupta2020hybrid}
for faster solving Mixed-Integer Linear Programming (\gls{MILP}) problems. 
Efficient \gls{MILP} solution algorithms are important for real-time optimization in various industries, including industrial production, logistics, transportation, and energy production \cite{junger2010years}.  % Reduced computation time via merging Machine learning with the Branch and Bound solution algorithm can improve these algorithms without sacrificing the strong benefits global optimization has over purely data-driven methods.
Multiple central researchers within mathematical programming and machine learning have recently shown interest in the application of Machine Learning in \gls{MILP} \cite{bengio2020machine,bertsimas2019online}. Particularly the variable selection part of the branching strategy has proved to be a field where machine learning methods can give promising results \cite{khalil2020towards}.
In 2019, reliable results of improvement over top branching strategies in open-source solvers were shown \cite{gasse2019exact}, and in 2020 these methods have been expanded to purely \gls{CPU}-based solutions \cite{gupta2020hybrid}. Multi-Layer Perceptrons are included in Gupta et al. \cite{gupta2020hybrid}, however their efficiency is not reported, and neither is it clear whether their configuration is significant to the resulting solution time.

In order to address this, three Multi-Layer Perceptron configurations are trained via imitation learning on the Strong Branching algorithm on generated \gls{MILP} problems, in the same manner as in Gupta et al. \cite{gupta2020hybrid}. The models are then incorporated into the \gls{SCIP} optimization solver and evaluated on test problems of various sizes. All models show near state-of-the-art efficiency, while the single-layer \gls{MLP} shows the most improvement over the Pseudo-cost and Reliability Pseudo-cost strategies. 
Future research should attempt to implement these methods on practical optimization problems, as well as compare results to the current top proprietary solvers after parameter optimization \cite{hutter2010automated}. Analysis of the contribution from the different input features of the learned branching strategies might also lead to interesting insights into the variable selection problem. 

The code for this project is available at\\ \url{https://github.com/Sandbergo/learn2branch}
%
\clearpage
