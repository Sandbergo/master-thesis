%!TEX root = ../thesis.tex
\chapter*{\englishabstractname}
\addcontentsline{toc}{chapter}{\englishabstractname}
% Multilayer Perceptrons for Learning to Branch
%
This project evaluates Multi-layer Perceptrons and Graph Convolutional Neural Networks for machine learning aided branching proposed by Gupta et al. \cite{gupta2020hybrid} and others
for faster solving Mixed-Integer Linear Programming (\gls{MILP}) problems. 
Efficient \gls{MILP} solution algorithms are important for real-time optimization in various industries, including industrial production, logistics, transportation, and energy production \cite{junger2010years}.  % Reduced computation time via merging Machine learning with the Branch and Bound solution algorithm can improve these algorithms without sacrificing the strong benefits global optimization has over purely data-driven methods.
Multiple central researchers within mathematical programming and machine learning have recently shown interest in the application of Machine Learning in \gls{MILP} \cite{bengio2020machine,bertsimas2019online}. Particularly the variable selection part of the branching strategy has proved to be a field where machine learning methods can give promising results \cite{khalil2020towards}.
In 2019, reliable results of improvement over top branching strategies in open-source solvers were shown \cite{gasse2019exact}, and in 2020 these methods have been expanded to purely \gls{CPU}-based solutions \cite{gupta2020hybrid}. Different network topologies and feature sets on both \gls{CPU}s and \gls{GPU}s have been presented, however the trade-off between accuracy and efficiency with these models on varying hardware is still mostly unexplored  

In order to address this, two variants of Graph Convolutional Neural Networks and three Multi-Layer Perceptron configurations are trained via imitation learning on the Strong Branching algorithm on generated \gls{MILP} problems, in the same manner as in Gupta et al. \cite{gupta2020hybrid} and using the new framework \textit{Ecole} \cite{prouvost2020ecole}.  The models are then incorporated into the \gls{SCIP} optimization solver and evaluated on test problems of various sizes. \textit{All models show near state-of-the-art efficiency, while the single-layer \gls{MLP} shows the most improvement over the Pseudo-cost and Reliability Pseudo-cost strategies. }
Future research should attempt to implement these methods on practical optimization problems, as well as compare results to the current top proprietary solvers after parameter optimization \cite{hutter2010automated}. Analysis of the contribution from the different input features of the learned branching strategies might also lead to interesting insights into the variable selection problem. 

The code for this project is available at\\ \url{https://github.com/Sandbergo/branch2learn}
%
\clearpage
