\chapter{Results}\label{cha:results}

In this chapter, the results of the experiments are reported, as described in \Cref{cha:methods}.


\section{Dataset Generation}

Problem instances are generated as described in \Cref{ssec:probleminstances}. In total, $10000$ training instances, $2000$ validation instances and $ 100 $ test instances of size $100 \times 500$, $200 \times 1000$ and $300 \times 1500$ are created. This is shown in \Cref{tab:instances}.

The generated problem instances are then solved as specified in \Cref{ssec:expertsolutiongeneration}. This results in a total of $162293$ training samples, i.e. nodes with the corresponding evaluation of candidate variables, and $30008$ validation samples. 

\begin{scriptsize}
\begin{table}[ht]
	\centering
	\begin{tabular}{lccccc}
		\toprule
		  Data set& \multicolumn{1}{c}{Train} & \multicolumn{1}{c}{Validate} & \multicolumn{3}{c}{Test}\\ \cmidrule(lr){2-2} \cmidrule(lr){3-3} \cmidrule(lr){4-6}
		  Dimensions & $100 \times 500$ & $100 \times 500$ & $100 \times 500$ & $200 \times 1000$ & $300 \times 1500$ \\
		\addlinespace
		% \midrule
		Instances & 10000 &  2000  & 100 & 20 & 20 \\
		% \addlinespace
		\bottomrule
	\end{tabular}
	\caption{Data set, dimensions and number of problem instances}\label{tab:instances}
\end{table}
\end{scriptsize}

\section{Training}

The training was performed as described in \Cref{sec:trainingprotocol}. 
The training graph for MLP3 is shown in \Cref{fig:training}. The Training and validation loss quickly converges before flattening out. There is no discernible difference between training and validation loss. Loss graphs for MLP1 and MLP2 are not shown, as they are very similar to MLP3's, and are therefore not of interest. 
%
\begin{figure}[h]
    \centering
    \includegraphics[width=\textwidth]{img/loss70.eps}
    \caption{Training graph for MLP3.}
    \label{fig:training}
\end{figure}


\section{Accuracy}


\begin{scriptsize}
\begin{table}[ht]
	\centering
	\begin{tabular}{lrrrrrrr}
		\toprule
		& \multicolumn{3}{c}{Combinatorial Auction} & \multicolumn{3}{c}{Set Covering}\\ 
		\cmidrule(lr){2-4} \cmidrule(lr){5-7}
		Model & acc@1 & acc@5 & acc@10 & acc@1 & acc@5 & acc@10 \\
		\midrule
		MLP1 & 30.3 \% & 62.8 \% & 79.4 \% & 0 & 0 & 0\\
		MLP2 & 50.1 \% & 78.9 \% & 89.9 \% & 0 & 0 & 0\\
		MLP3 & 50.2 \% & 79.3 \% & 90.1 \% & 0 & 0 & 0\\
		GNN1 & 53.0 \% & 87.5 \% & 95.9 \% & 0 & 0 & 0\\
		GNN2 & 53.0 \% & 87.1 \% & 96.0 \% & 0 & 0 & 0\\
		\addlinespace
		\bottomrule
	\end{tabular}
	\caption{Top-k accuracy scores for combinatorial auctions and set covering.}\label{tab:results1_set}
\end{table}
\end{scriptsize}

% MLP1 0.30329361 0.43040384 0.5133234  0.57414763 0.62793777 0.66972857
%0.70506455 0.7397385  0.76903343 0.79443893

%[0.50099305 0.61717974 0.69298246 0.7469381  0.78930818 0.82000993
%0.84640847 0.86701423 0.88339954 0.89920556]

% 0.50281364 0.61924859 0.69546508 0.75       0.79319762 0.82116849
% 0.84789805 0.8683383  0.8857994  0.90143992]

% [0.52962595 0.68884475 0.7744952  0.8326713  0.87520689 0.90292949
% 0.92303873 0.938762   0.95076134 0.95945051]

% [0.52962595 0.68636213 0.7744952  0.83325058 0.87065541 0.90052963
% 0.92171466 0.93776895 0.95092685 0.96027805]
 

The top-k accuracy scores for the three \gls{MLP}s along with the benchmark accuracy for random variable selection is shown in \Cref{fig:topk}. Top k accuracy is defined as the number of selected branching variables within the top k variables as determined by the Strong Branching evaluation. 
% https://scikit-learn.org/dev/modules/model_evaluation.html#top-k-accuracy-score

MLP2 and MLP3 show near-identical accuracy, with MLP3 consistently outperformed by 2 - 3 \% at each category. Comparison with the random variable selection policy shows a considerable improvement in favor of the trained models. 

\begin{figure}
    \begin{tikzpicture}
      \begin{axis}[
        mlineplot,
        ylabel={Accuracy [\%]},
        xlabel={Top k},
        width=\textwidth,
        height=7cm,
	    ymin=0.0,   ymax=1.0,
	    xtick=data,
	    legend style={at={(0.01,0.9)},anchor=west}
      ]
        \addplot plot coordinates{(1, 0.413) (2, 0.538) (3, 0.621) (4, 0.681) (5, 0.732) (6, 0.770) (7, 0.800) (8, 0.827) (9, 0.849) (10, 0.867)};
        \addplot plot coordinates{(1, 0.437) (2, 0.568) (3, 0.653) (4, 0.717) (5, 0.767) (6, 0.805) (7, 0.835) (8, 0.860) (9, 0.881) (10, 0.899)};
        \addplot plot coordinates{(1, 0.435) (2, 0.568) (3, 0.652) (4, 0.716) (5, 0.765) (6, 0.802) (7, 0.831) (8, 0.858) (9, 0.879) (10, 0.897)};
        \addplot+ plot coordinates{(1, 0.019) (2, 0.034) (3, 0.047) (4, 0.060) (5, 0.071) (6, 0.081) (7, 0.090) (8, 0.098) (9, 0.107) (10, 0.115)};
        %\addplot+[samples=100] {sin(deg(2*x))};
        \legend{MLP1,MLP2,MLP3,Random}
        
      \end{axis}
    \end{tikzpicture}
    \caption{Top k accuracy of trained models and random variable selection on test set. MLP2 and MLP3 nearly indistinguishable.}
    \label{fig:topk}
\end{figure}
% 0 0.0 acc@1: 43.7 acc@2: 56.8 acc@3: 65.4 acc@4: 71.7 acc@5: 76.6 acc@6: 80.3 acc@7: 83.3 acc@8: 85.9 acc@9: 88.0 acc@10: 89.9

% 61 acc@0:  0.0 acc@1: 41.3 acc@2: 53.8 acc@3: 62.1 acc@4: 68.1 acc@5: 73.2 acc@6: 77.0 acc@7: 80.0 acc@8: 82.7 acc@9: 84.9 acc@10: 86.7

% 70 acc@0:  0.0 acc@1: 43.5 acc@2: 56.8 acc@3: 65.2 acc@4: 71.6 acc@5: 76.5 acc@6: 80.2 acc@7: 83.1 acc@8: 85.8 acc@9: 87.9 acc@10: 89.7


\section{Efficiency}

Five branching strategies were compared on the problem data set of three different problem sizes. The branching strategies are Full Strong Branching, Reliability Pseudo-cost branching, and the three \gls{MLP} topologies. The results are shown in \Cref{tab:results1_cauction}. \textit{Time} is the mean solution time, \textit{nodes} is the mean number of nodes in the solution graphs (calculated in accordance with the findings of Gamrath et al. \cite{gamrath2018measuring}), \textit{completed} is the number of problems where optimality was achieved within the time limit of 45 minutes and is only applicable for the large problem size. The branching strategy with the shortest mean solution time is marked bold for each problem size. 

The low-capacity MLP1 branching strategy clearly wins for small problem sizes and is slightly better for medium problem sizes. For large problem sizes, Reliability Pseudo-cost Branching is decisively better, with less than half the solution time of the \gls{MLP} strategies. 

Full Strong Branching results in solution trees orders of magnitude smaller than the \gls{MLP} counterpart. MLP1 is consistently performing faster branching than the other strategies, with respectively $8 \%, 23 \%, 48 \%$ more nodes processed than MLP2 for the three problem sizes.

\Cref{fig:barplot} shows the results for the small problem size from \Cref{tab:results1_cauction}, including $95 \%$ confidence intervals.
% \usepackage{booktabs}
 
  
\begin{scriptsize}
\begin{table}[ht]
	\centering
	\begin{tabular}{lrrrrrrr}
		\toprule
		Model & Time (s) & Nodes  & Time/node (ms) & parameters \\
		\midrule
		FSB & 0 & 0 & 0 & 0 & 0 & 0 & 0 / 20\\
		PC  & $7.78 \pm 9.50$ & $749 \pm 1634$ & 0 & 0\\
		RPC & $10.68 \pm 8.01$ & $295 \pm 895$ 0 & 0\\
		\addlinespace
		MLP1\textsubscript{g} & $36.89 \pm 57.71$ & $2232 \pm 3442$ & 0 & 0\\
		MLP2\textsubscript{g} & $16.24 \pm 27.27$ & $545 \pm 1120$  & 0 & 0\\
		MLP3\textsubscript{g} & $16.45 \pm 22.58$ & $515 \pm 808 $  & 0 & 0\\
		GNN1\textsubscript{g} & $11.63 \pm 16.66$ & $272 \pm 506 $  & 0 & 0\\
		GNN2\textsubscript{g} & $11.18 \pm 11.51$ & $264 \pm 357 $  & 0 & 0\\
		\addlinespace
		MLP1\textsubscript{c} & $39.70 \pm 55.09$ & $2242 \pm 3486$ & 0 & 0\\
		MLP2\textsubscript{c} & $16.70 \pm 17.78$ & $513 \pm 720$   & 0 & 0\\
		MLP3\textsubscript{c} & $17.69 \pm 22.25$ & $502 \pm 867$   & 0 & 0\\
		GNN1\textsubscript{c} & $68.59 \pm 97.11$ & $308 \pm 460$   & 0 & 0\\
		GNN2\textsubscript{c} & $72.37 \pm 112.80$ & $324 \pm 523$  & 0 & 0\\
		\bottomrule
	\end{tabular}
	\caption{Setcover solving efficiency.}\label{tab:results1_set}
\end{table}
\begin{table}[ht]
	\centering
	\begin{tabular}{lrrrrrrr}
	    \toprule
		Model & Time (s) & Nodes  & Time/node (ms) & parameters \\
		\midrule
		FSB & 0 & 0 & 0 & 0 & --- \\
		PC  & $1.96 \pm 0.84$ & $355 \pm 358$ & $5.5$ & ---\\
		RPC & $2.73 \pm 1.18$ & $16 \pm 30$ & $ 171.1$ & ---\\
		\addlinespace
		MLP1\textsubscript{g} & $1.84 \pm 0.83$ & $282 \pm 362$ & $6.5$  & 0\\
		MLP2\textsubscript{g} & $1.60 \pm 0.44$ & $123 \pm 116$ & $13.0$ & 0\\
		MLP3\textsubscript{g} & $1.62 \pm 0.45$ & $121 \pm 112$ & $13.4$ & 0\\
		GNN1\textsubscript{g} & $1.65 \pm 0.45$ & $97 \pm 85$   & $17.0$ & 0\\
		GNN2\textsubscript{g} & $1.63 \pm 0.44$ & $95 \pm 80$   & $17.2$ & 0\\
		\addlinespace
		MLP1\textsubscript{c} & $1.78 \pm 0.78$ & $280 \pm 394$ & $6.4$  & 0\\
		MLP2\textsubscript{c} & $3.12 \pm 1.28$ & $123 \pm 114$ & $25.4$ & 0\\
		MLP3\textsubscript{c} & $3.24 \pm 1.35$ & $120 \pm 112$ & $27.0$ & 0\\
		GNN1\textsubscript{c} & $5.06 \pm 2.80$ & $96 \pm 81$   & $52.7$ & 0\\
		GNN2\textsubscript{c} & $5.10 \pm 2.92$ & $97 \pm 81$   & $52.6$ & 0\\
		\bottomrule
	\end{tabular}
	\caption{Combinatorial auction solving efficiency.}\label{tab:results1_cauction}
\end{table}
\end{scriptsize}

\begin{figure}
    \centering
    \begin{tikzpicture}
        \begin{axis}[
          width=12cm,
          height=7cm,
          axis x line*=bottom,
          axis y line*=left,
          % nodes near coords,
          legend style={
            at={(0.5,-0.15)},
            anchor=north,
            legend columns=-1
          },
          xtick={1,2,3,4,5,6},
          xticklabels={SB,PB,RPB,MLP1,MLP2,MLP3}, 
          x tick label style={rotate=45,anchor=east},
          ymin=0,
          ymax=8,
          ybar=5pt,
          bar width=0.4cm,
          ylabel={Solution Time [\si{s}]},
          ymajorgrids=true,
          ytick={2,4,...,20}
        ]
          \addplot[color=black,fill=lightgray,error bars/.cd,
    y dir=both,y explicit] coordinates {
            (1,5.4) +- (0.0, 0.6)  %3.27)
            (2,2.5) +- (0.0, 0.24)  %1.2)
            (3,3.7) +- (0.0, 0.37) %1.9)
            (4,2.1) +- (0.0, 0.16) %0.83)
            (5,2.3) +- (0.0, 0.18) %0.93)
            (6,3.0) +- (0.0, 0.33) %1.67)
          };
        \end{axis}
  \end{tikzpicture}
  \caption{Mean solution time with 95 \% confidence intervals for small combinatorial auction problems, n = 100.}
    \label{fig:barplot}
\end{figure}




\subsection{Model Comparison}

\begin{figure}
    \centering
    \begin{tikzpicture}
    
      \def\MarkSize{.75em}
      \protected\def\ToWest#1{%
        \llap{#1\kern\MarkSize}\phantom{#1}%
      }
      \protected\def\ToSouth#1{%
        \sbox0{#1}%
        \smash{%
          \rlap{%
            \kern-.5\dimexpr\wd0 + \MarkSize\relax
            \lower\dimexpr.375em+\ht0\relax\copy0 %
          }%
        }%
        \hphantom{#1}%
      }
    \begin{axis}[ xlabel={CPU time}, ylabel={GPU time}, width=10cm, height=10cm, ymin=1.0, ymax=5.5, xmin=1.0,   xmax=5.5, ymajorgrids=true,
    xmajorgrids=true,]v
    \addplot[scatter,mark=*,only marks, point meta=x,nodes near coords*={\data},
    visualization depends on={value \thisrow{dataname} \as \data},] 
    table [x=x,y=y]{
    x       y       dataname
    1.84    1.78    MLP1
    1.60    3.12    \ToSouth{MLP2}
    1.62    3.24    MLP3
    1.65    5.06    \ToSouth{GNN1}
    1.63    5.10    GNN2
    };
    \end{axis}
    \end{tikzpicture}
    \caption{Combinatorial Auction small problem mean solution time GPU and CPU.}
    \label{fig:gpu_cpu}
\end{figure}



\subsection{Learned and Classical Branching Comparison}

% including transfer learning 

\begin{scriptsize}
\begin{table}[ht]
	\centering
	\begin{tabular}{lrrrrrrr}
		\toprule
		& \multicolumn{2}{c}{Small} & \multicolumn{2}{c}{Medium} & \multicolumn{3}{c}{Large}\\ \cmidrule(lr){2-3} \cmidrule(lr){4-5} \cmidrule(lr){6-8}
		Model & Time (s) & Nodes  & Time (s) & Nodes & Time (s) & Nodes & Completed\\
		\midrule
		FSB & 0 & 0 & 0 & 0 & 0 & 0 & 0 / 20\\
		PC  & $7.78 \pm 9.50$ & $749 \pm 1634$ & 0 & 0 & 0 & 0 & 0 / 20\\
		RPC & 0 & 0 & 0 & 0 & 0 & 0 & 0 / 20\\
		\addlinespace
		MLP1\textsubscript{g} & $36.89 \pm 57.71$ & $2232 \pm 3442$ & 0 & 0 & 0 & 0 & 0 / 20\\
		MLP2\textsubscript{g} & $16.24 \pm 27.27$ & $545 \pm 1120$ & 0 & 0 & 0 & 0 & 0 / 20\\
		GNN1\textsubscript{g} & $11.63 \pm 16.66$ & $272 \pm 506 $& 0 & 0 & 0 & 0 & 0 / 20\\
		\addlinespace
		MLP1\textsubscript{c} & $39.70 \pm 55.09$ & $2242 \pm 3486$ & 0 & 0 & 0 & 0 & 0 / 20\\
		MLP2\textsubscript{c} & $16.70 \pm 17.78$ & $513 \pm 720$ & 0 & 0 & 0 & 0 & 0 / 20\\
		GNN1\textsubscript{c} & $68.59 \pm 97.11$ & $308 \pm 460$ & 0 & 0 & 0 & 0 & 0 / 20\\
		\bottomrule
	\end{tabular}
	\caption{Setcover solving time on larger problem sets.}\label{tab:results_trans_set}
\end{table}
\begin{table}[ht]
	\centering
	\begin{tabular}{lrrrrrrr}
	    \toprule
		& \multicolumn{2}{c}{Small} & \multicolumn{2}{c}{Medium} & \multicolumn{3}{c}{Large}\\ \cmidrule(lr){2-3} \cmidrule(lr){4-5} \cmidrule(lr){6-8}
		Model & Time (s) & Nodes  & Time (s) & Nodes & Time (s) & Nodes & Completed\\
		\midrule
		FSB & 0 & 0 & 0 & 0 & 0 & 0 & 0 / 20\\
		PC  & $1.96 \pm 0.84$ & $355 \pm 358$ & 0 & 0 & 0 & 0 & 0 / 20\\
		RPC & 0 & 0 & 0 & 0 & 0 & 0 & 0 / 20\\
		\addlinespace
		MLP1\textsubscript{g} & $1.84 \pm 0.83$ & $282 \pm 362$ & 0 & 0 & 0 & 0 & 0 / 20\\
		MLP2\textsubscript{g} & $1.60 \pm 0.44$ & $123 \pm 116$ & 0 & 0 & 0 & 0 & 0 / 20\\
		GNN1\textsubscript{g} & $1.65 \pm 0.45$ & $97 \pm 85$ & 0 & 0 & 0 & 0 & 0 / 20\\
		\addlinespace
		MLP1\textsubscript{c} & $1.78 \pm 0.78$ & $280 \pm 394$ & 0 & 0 & 0 & 0 & 0 / 20\\
		MLP2\textsubscript{c} & $3.12 \pm 1.28$ & $123 \pm 114$ & 0 & 0 & 0 & 0 & 0 / 20\\
		GNN1\textsubscript{c} & $5.06 \pm 2.80$ & $96 \pm 81$ & 0 & 0 & 0 & 0 & 0 / 20\\
		\bottomrule
	\end{tabular}
	\caption{Combinatorial auction solving efficiency on larger problem sets.}\label{tab:results_trans_cauction}
\end{table}
\end{scriptsize}
% include feature importance

% include solution hists nnodes

\begin{figure}[h]
    \centering
    \includegraphics[width=\textwidth]{img/loss70.eps}
    \caption{Histogram of nodes for pseudo cost branching and MLP2.}
    \label{fig:node_histogram}
\end{figure}

